{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penguin/miniconda3/envs/research/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from hope.models.segmodel import SegModel\n",
    "import torch\n",
    "from hope.utils.embed import create_embs_from_names\n",
    "import cv2\n",
    "from hope.utils.transform_utils import resize_by_scaled_short_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegModel(criterions=None,\n",
    "                     num_classes=512,\n",
    "                     load_imagenet_model=False, imagenet_ckpt_fpath='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegModel(\n",
       "  (segmodel): SegFormer(\n",
       "    (encoder): mit_b5(\n",
       "      (patch_embed1): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (patch_embed2): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (patch_embed3): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (patch_embed4): OverlapPatchEmbed(\n",
       "        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (block1): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.002)\n",
       "          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.004)\n",
       "          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      (block2): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.006)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.008)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.010)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.012)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.014)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.016)\n",
       "          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (block3): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.020)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.022)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.024)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.025)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.029)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.031)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.033)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.035)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.037)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.041)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.043)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.045)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.047)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.049)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.051)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.053)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.057)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.059)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.061)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.063)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (24): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (25): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.067)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (26): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.069)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (27): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.071)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (28): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (29): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.075)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (30): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.076)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (31): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (32): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.080)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (33): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.082)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (34): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.084)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (35): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.086)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (36): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.088)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (37): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.090)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (38): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.092)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (39): Block(\n",
       "          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.094)\n",
       "          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "      (block4): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.096)\n",
       "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.098)\n",
       "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (dwconv): DWConv(\n",
       "              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (head): SegFormerHead(\n",
       "      (conv_seg): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "      (linear_c4): MLP(\n",
       "        (proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      )\n",
       "      (linear_c3): MLP(\n",
       "        (proj): Linear(in_features=320, out_features=768, bias=True)\n",
       "      )\n",
       "      (linear_c2): MLP(\n",
       "        (proj): Linear(in_features=128, out_features=768, bias=True)\n",
       "      )\n",
       "      (linear_c1): MLP(\n",
       "        (proj): Linear(in_features=64, out_features=768, bias=True)\n",
       "      )\n",
       "      (linear_fuse): ConvModule(\n",
       "        (conv): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): SyncBatchNorm(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (linear_pred): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (auxi_net): FCNHead(\n",
       "      (convs): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_seg): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/home/penguin/SSIW/data/model/segformer_7data.pth', map_location='cpu')['state_dict']\n",
    "ckpt_filter = {k: v for k, v in checkpoint.items() if 'criterion.0.criterion.weight' not in k}\n",
    "maybe_errors = model.load_state_dict(ckpt_filter, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/penguin/SSIW/Test_Minist/cmp_dataset_desc.json', 'r', encoding='utf-8') as f:\n",
    "    new_definitions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_label = ['background','facade','window','door', 'cornice', 'sill', 'balcony', 'blind','deco', 'molding', 'pillar', 'shop', 'unlabel']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_embs_list = create_embs_from_names(user_label, new_definitions).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.imread('/home/penguin/SSIW/data/base/cmp_b0001.jpg', -1)[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized = resize_by_scaled_short_side(rgb, 720, 1)\n",
    "h, w, _ = rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hope.utils.transform_utils import single_scale_single_crop_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE MODEL EMBED:  tensor([[[[ 0.9677,  0.9555,  0.9432,  ...,  0.4785,  0.4577,  0.4370],\n",
      "          [ 1.0237,  0.9959,  0.9681,  ...,  0.5186,  0.4955,  0.4723],\n",
      "          [ 1.0796,  1.0363,  0.9930,  ...,  0.5588,  0.5332,  0.5076],\n",
      "          ...,\n",
      "          [ 1.4984,  1.4334,  1.3684,  ...,  1.2053,  1.2261,  1.2469],\n",
      "          [ 1.5373,  1.5072,  1.4771,  ...,  1.2232,  1.2122,  1.2012],\n",
      "          [ 1.5762,  1.5810,  1.5858,  ...,  1.2411,  1.1983,  1.1556]],\n",
      "\n",
      "         [[ 1.1118,  1.0646,  1.0175,  ...,  2.6556,  2.6401,  2.6246],\n",
      "          [ 1.2082,  1.1665,  1.1248,  ...,  2.7158,  2.7480,  2.7803],\n",
      "          [ 1.3045,  1.2683,  1.2320,  ...,  2.7760,  2.8560,  2.9359],\n",
      "          ...,\n",
      "          [ 3.0590,  2.9372,  2.8154,  ...,  2.1309,  2.2640,  2.3971],\n",
      "          [ 3.1216,  3.0577,  2.9939,  ...,  2.1646,  2.2413,  2.3181],\n",
      "          [ 3.1841,  3.1782,  3.1723,  ...,  2.1983,  2.2186,  2.2390]],\n",
      "\n",
      "         [[ 5.6221,  5.5498,  5.4774,  ...,  7.1191,  7.0593,  6.9995],\n",
      "          [ 5.6971,  5.5823,  5.4676,  ...,  7.0413,  7.0641,  7.0869],\n",
      "          [ 5.7720,  5.6149,  5.4577,  ...,  6.9634,  7.0689,  7.1743],\n",
      "          ...,\n",
      "          [ 7.7789,  7.5440,  7.3092,  ...,  8.2280,  8.4262,  8.6244],\n",
      "          [ 7.9586,  7.8760,  7.7933,  ...,  8.5770,  8.5586,  8.5402],\n",
      "          [ 8.1384,  8.2079,  8.2775,  ...,  8.9260,  8.6910,  8.4560]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.1010, -3.0597, -3.0185,  ..., -3.3748, -3.3325, -3.2902],\n",
      "          [-3.1621, -3.1166, -3.0711,  ..., -3.4175, -3.4016, -3.3856],\n",
      "          [-3.2233, -3.1735, -3.1237,  ..., -3.4602, -3.4706, -3.4811],\n",
      "          ...,\n",
      "          [-4.7946, -4.7126, -4.6306,  ..., -5.3023, -5.3455, -5.3886],\n",
      "          [-4.8350, -4.8129, -4.7907,  ..., -5.4258, -5.4060, -5.3861],\n",
      "          [-4.8755, -4.9131, -4.9507,  ..., -5.5493, -5.4665, -5.3837]],\n",
      "\n",
      "         [[ 5.0198,  4.9729,  4.9259,  ...,  6.0618,  6.0150,  5.9682],\n",
      "          [ 5.1092,  5.0020,  4.8948,  ...,  6.0321,  6.0450,  6.0578],\n",
      "          [ 5.1986,  5.0312,  4.8637,  ...,  6.0025,  6.0749,  6.1474],\n",
      "          ...,\n",
      "          [ 6.7256,  6.5741,  6.4226,  ...,  8.0045,  8.1608,  8.3171],\n",
      "          [ 6.8411,  6.8019,  6.7628,  ...,  8.1689,  8.1611,  8.1534],\n",
      "          [ 6.9566,  7.0297,  7.1029,  ...,  8.3333,  8.1615,  7.9896]],\n",
      "\n",
      "         [[ 1.1456,  1.1574,  1.1692,  ...,  1.7611,  1.7240,  1.6869],\n",
      "          [ 1.2080,  1.2106,  1.2132,  ...,  1.7857,  1.7768,  1.7678],\n",
      "          [ 1.2703,  1.2637,  1.2571,  ...,  1.8103,  1.8295,  1.8488],\n",
      "          ...,\n",
      "          [ 1.0398,  1.0169,  0.9940,  ...,  1.6967,  1.7055,  1.7144],\n",
      "          [ 1.0872,  1.0827,  1.0781,  ...,  1.7989,  1.7746,  1.7503],\n",
      "          [ 1.1347,  1.1484,  1.1622,  ...,  1.9010,  1.8436,  1.7862]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "out_logit, emb = single_scale_single_crop_cuda(model, image_resized, h, w, gt_embs_list=gt_embs_list, args=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.30377680e-04, 7.89794028e-01, 7.67565425e-03, ...,\n",
       "         6.36376217e-02, 7.25746527e-02, 6.25764718e-04],\n",
       "        [7.74360436e-04, 7.97130048e-01, 6.53548725e-03, ...,\n",
       "         7.63333440e-02, 6.15738556e-02, 6.96829404e-04],\n",
       "        [8.22321395e-04, 7.98902333e-01, 5.60233276e-03, ...,\n",
       "         9.12014246e-02, 5.22993207e-02, 7.74080167e-04],\n",
       "        ...,\n",
       "        [3.27872316e-04, 9.11018610e-01, 4.28098254e-03, ...,\n",
       "         3.81366424e-02, 2.08857302e-02, 3.42788117e-04],\n",
       "        [2.94951111e-04, 9.11164701e-01, 4.30622045e-03, ...,\n",
       "         3.53606194e-02, 2.25036740e-02, 2.89288757e-04],\n",
       "        [2.64814385e-04, 9.10337687e-01, 4.35221940e-03, ...,\n",
       "         3.28608938e-02, 2.44434718e-02, 2.42088572e-04]],\n",
       "\n",
       "       [[1.12461124e-03, 7.12043285e-01, 1.09147439e-02, ...,\n",
       "         1.31265298e-01, 8.20370466e-02, 7.01031182e-04],\n",
       "        [1.17005152e-03, 7.27108717e-01, 7.71105802e-03, ...,\n",
       "         1.54981747e-01, 6.40132129e-02, 7.93138053e-04],\n",
       "        [1.21196837e-03, 7.30345488e-01, 5.56345563e-03, ...,\n",
       "         1.79018438e-01, 5.04255220e-02, 8.85811984e-04],\n",
       "        ...,\n",
       "        [5.06628305e-04, 8.75484288e-01, 4.90619149e-03, ...,\n",
       "         7.48608708e-02, 2.40269639e-02, 3.97940807e-04],\n",
       "        [4.39839787e-04, 8.75629544e-01, 5.13321813e-03, ...,\n",
       "         6.91029578e-02, 2.74846368e-02, 3.23290180e-04],\n",
       "        [3.77604913e-04, 8.73793662e-01, 5.42421825e-03, ...,\n",
       "         6.34733588e-02, 3.19767483e-02, 2.57517939e-04]],\n",
       "\n",
       "       [[1.53095485e-03, 6.17517769e-01, 1.39213353e-02, ...,\n",
       "         2.23126411e-01, 8.63202363e-02, 7.37853523e-04],\n",
       "        [1.54430454e-03, 6.38760269e-01, 8.41659494e-03, ...,\n",
       "         2.52820283e-01, 6.27871007e-02, 8.42013222e-04],\n",
       "        [1.55109493e-03, 6.44653082e-01, 5.30644786e-03, ...,\n",
       "         2.78115243e-01, 4.66908440e-02, 9.41939768e-04],\n",
       "        ...,\n",
       "        [6.89318927e-04, 8.31305742e-01, 5.36092417e-03, ...,\n",
       "         1.19410649e-01, 2.62462478e-02, 4.41065116e-04],\n",
       "        [5.89041156e-04, 8.30970526e-01, 5.79541223e-03, ...,\n",
       "         1.11866154e-01, 3.15258354e-02, 3.49071575e-04],\n",
       "        [4.94258886e-04, 8.27647090e-01, 6.37157261e-03, ...,\n",
       "         1.03959389e-01, 3.89189422e-02, 2.68097327e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[5.43775641e-05, 9.08304393e-01, 7.82442512e-05, ...,\n",
       "         9.32185445e-03, 5.93547225e-02, 2.29630496e-05],\n",
       "        [7.37343944e-05, 9.02658463e-01, 8.70997392e-05, ...,\n",
       "         1.15169380e-02, 6.05675913e-02, 2.38955472e-05],\n",
       "        [9.70976325e-05, 8.96929502e-01, 9.66534426e-05, ...,\n",
       "         1.39133781e-02, 6.16880320e-02, 2.49848708e-05],\n",
       "        ...,\n",
       "        [3.03659996e-04, 9.88417149e-01, 2.02285992e-05, ...,\n",
       "         3.62756127e-03, 6.96050934e-03, 4.22535813e-04],\n",
       "        [2.80769891e-04, 9.88526106e-01, 1.81242667e-05, ...,\n",
       "         3.76968412e-03, 6.73155766e-03, 4.45087993e-04],\n",
       "        [2.58355867e-04, 9.88623261e-01, 1.61804655e-05, ...,\n",
       "         3.92441358e-03, 6.49325876e-03, 4.71190142e-04]],\n",
       "\n",
       "       [[6.05627465e-05, 9.11884069e-01, 1.01485224e-04, ...,\n",
       "         8.39466602e-03, 5.75503632e-02, 2.54435363e-05],\n",
       "        [7.58713868e-05, 9.05868888e-01, 1.12592737e-04, ...,\n",
       "         9.94216278e-03, 5.91460839e-02, 2.57391803e-05],\n",
       "        [9.34321724e-05, 8.99837852e-01, 1.24269049e-04, ...,\n",
       "         1.16023421e-02, 6.05875589e-02, 2.61611222e-05],\n",
       "        ...,\n",
       "        [2.75796192e-04, 9.90029037e-01, 1.61392418e-05, ...,\n",
       "         2.91515375e-03, 6.07215799e-03, 4.61556541e-04],\n",
       "        [2.63993978e-04, 9.89964485e-01, 1.49353409e-05, ...,\n",
       "         3.04863881e-03, 5.99774532e-03, 4.90856590e-04],\n",
       "        [2.52101570e-04, 9.89899099e-01, 1.38123805e-05, ...,\n",
       "         3.18791810e-03, 5.91301452e-03, 5.22961782e-04]],\n",
       "\n",
       "       [[6.85341001e-05, 9.15076375e-01, 1.33846042e-04, ...,\n",
       "         7.57037010e-03, 5.59130087e-02, 2.86629111e-05],\n",
       "        [7.94053049e-05, 9.08593297e-01, 1.49276297e-04, ...,\n",
       "         8.55118502e-03, 5.78880757e-02, 2.83015597e-05],\n",
       "        [9.11991519e-05, 9.02030706e-01, 1.65253005e-04, ...,\n",
       "         9.57935769e-03, 5.96740209e-02, 2.80486365e-05],\n",
       "        ...,\n",
       "        [2.47475458e-04, 9.91602898e-01, 1.23727223e-05, ...,\n",
       "         2.24121055e-03, 5.16522210e-03, 5.18017099e-04],\n",
       "        [2.47301155e-04, 9.91341949e-01, 1.19823872e-05, ...,\n",
       "         2.37929937e-03, 5.25448052e-03, 5.54028084e-04],\n",
       "        [2.46690848e-04, 9.91086781e-01, 1.16164256e-05, ...,\n",
       "         2.52009160e-03, 5.33280335e-03, 5.91526623e-04]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0174,  0.0173,  0.0172,  ...,  0.0073,  0.0070,  0.0067],\n",
       "          [ 0.0181,  0.0179,  0.0177,  ...,  0.0079,  0.0076,  0.0072],\n",
       "          [ 0.0187,  0.0185,  0.0182,  ...,  0.0086,  0.0081,  0.0076],\n",
       "          ...,\n",
       "          [ 0.0175,  0.0172,  0.0167,  ...,  0.0128,  0.0129,  0.0129],\n",
       "          [ 0.0178,  0.0175,  0.0172,  ...,  0.0126,  0.0126,  0.0126],\n",
       "          [ 0.0180,  0.0178,  0.0177,  ...,  0.0125,  0.0124,  0.0123]],\n",
       "\n",
       "         [[ 0.0200,  0.0193,  0.0186,  ...,  0.0403,  0.0404,  0.0404],\n",
       "          [ 0.0214,  0.0210,  0.0206,  ...,  0.0416,  0.0419,  0.0423],\n",
       "          [ 0.0226,  0.0226,  0.0226,  ...,  0.0429,  0.0435,  0.0441],\n",
       "          ...,\n",
       "          [ 0.0358,  0.0351,  0.0344,  ...,  0.0226,  0.0238,  0.0249],\n",
       "          [ 0.0361,  0.0355,  0.0349,  ...,  0.0224,  0.0233,  0.0243],\n",
       "          [ 0.0363,  0.0358,  0.0354,  ...,  0.0222,  0.0229,  0.0238]],\n",
       "\n",
       "         [[ 0.1012,  0.1006,  0.1001,  ...,  0.1081,  0.1080,  0.1078],\n",
       "          [ 0.1007,  0.1005,  0.1002,  ...,  0.1078,  0.1078,  0.1078],\n",
       "          [ 0.1002,  0.1002,  0.1003,  ...,  0.1075,  0.1076,  0.1077],\n",
       "          ...,\n",
       "          [ 0.0911,  0.0903,  0.0894,  ...,  0.0873,  0.0884,  0.0895],\n",
       "          [ 0.0919,  0.0915,  0.0910,  ...,  0.0887,  0.0892,  0.0896],\n",
       "          [ 0.0927,  0.0926,  0.0924,  ...,  0.0900,  0.0899,  0.0898]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0558, -0.0555, -0.0552,  ..., -0.0512, -0.0510, -0.0507],\n",
       "          [-0.0559, -0.0561, -0.0563,  ..., -0.0523, -0.0519, -0.0515],\n",
       "          [-0.0560, -0.0567, -0.0574,  ..., -0.0534, -0.0528, -0.0523],\n",
       "          ...,\n",
       "          [-0.0561, -0.0564, -0.0566,  ..., -0.0563, -0.0561, -0.0559],\n",
       "          [-0.0558, -0.0559, -0.0559,  ..., -0.0561, -0.0563, -0.0565],\n",
       "          [-0.0556, -0.0554, -0.0553,  ..., -0.0559, -0.0565, -0.0572]],\n",
       "\n",
       "         [[ 0.0903,  0.0902,  0.0900,  ...,  0.0920,  0.0920,  0.0920],\n",
       "          [ 0.0903,  0.0900,  0.0897,  ...,  0.0924,  0.0923,  0.0922],\n",
       "          [ 0.0902,  0.0898,  0.0894,  ...,  0.0927,  0.0925,  0.0923],\n",
       "          ...,\n",
       "          [ 0.0788,  0.0787,  0.0785,  ...,  0.0849,  0.0856,  0.0863],\n",
       "          [ 0.0790,  0.0790,  0.0789,  ...,  0.0845,  0.0850,  0.0856],\n",
       "          [ 0.0793,  0.0793,  0.0793,  ...,  0.0840,  0.0844,  0.0848]],\n",
       "\n",
       "         [[ 0.0206,  0.0210,  0.0214,  ...,  0.0267,  0.0264,  0.0260],\n",
       "          [ 0.0213,  0.0218,  0.0222,  ...,  0.0273,  0.0271,  0.0269],\n",
       "          [ 0.0221,  0.0226,  0.0231,  ...,  0.0280,  0.0279,  0.0278],\n",
       "          ...,\n",
       "          [ 0.0122,  0.0122,  0.0122,  ...,  0.0180,  0.0179,  0.0178],\n",
       "          [ 0.0126,  0.0126,  0.0126,  ...,  0.0186,  0.0185,  0.0184],\n",
       "          [ 0.0129,  0.0130,  0.0130,  ...,  0.0192,  0.0191,  0.0190]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 543, 13), torch.Size([1, 512, 1376, 736]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_logit.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0174,  0.0173,  0.0172,  ...,  0.0073,  0.0070,  0.0067],\n",
       "          [ 0.0181,  0.0179,  0.0177,  ...,  0.0079,  0.0076,  0.0072],\n",
       "          [ 0.0187,  0.0185,  0.0182,  ...,  0.0086,  0.0081,  0.0076],\n",
       "          ...,\n",
       "          [ 0.0175,  0.0172,  0.0167,  ...,  0.0128,  0.0129,  0.0129],\n",
       "          [ 0.0178,  0.0175,  0.0172,  ...,  0.0126,  0.0126,  0.0126],\n",
       "          [ 0.0180,  0.0178,  0.0177,  ...,  0.0125,  0.0124,  0.0123]],\n",
       "\n",
       "         [[ 0.0200,  0.0193,  0.0186,  ...,  0.0403,  0.0404,  0.0404],\n",
       "          [ 0.0214,  0.0210,  0.0206,  ...,  0.0416,  0.0419,  0.0423],\n",
       "          [ 0.0226,  0.0226,  0.0226,  ...,  0.0429,  0.0435,  0.0441],\n",
       "          ...,\n",
       "          [ 0.0358,  0.0351,  0.0344,  ...,  0.0226,  0.0238,  0.0249],\n",
       "          [ 0.0361,  0.0355,  0.0349,  ...,  0.0224,  0.0233,  0.0243],\n",
       "          [ 0.0363,  0.0358,  0.0354,  ...,  0.0222,  0.0229,  0.0238]],\n",
       "\n",
       "         [[ 0.1012,  0.1006,  0.1001,  ...,  0.1081,  0.1080,  0.1078],\n",
       "          [ 0.1007,  0.1005,  0.1002,  ...,  0.1078,  0.1078,  0.1078],\n",
       "          [ 0.1002,  0.1002,  0.1003,  ...,  0.1075,  0.1076,  0.1077],\n",
       "          ...,\n",
       "          [ 0.0911,  0.0903,  0.0894,  ...,  0.0873,  0.0884,  0.0895],\n",
       "          [ 0.0919,  0.0915,  0.0910,  ...,  0.0887,  0.0892,  0.0896],\n",
       "          [ 0.0927,  0.0926,  0.0924,  ...,  0.0900,  0.0899,  0.0898]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0558, -0.0555, -0.0552,  ..., -0.0512, -0.0510, -0.0507],\n",
       "          [-0.0559, -0.0561, -0.0563,  ..., -0.0523, -0.0519, -0.0515],\n",
       "          [-0.0560, -0.0567, -0.0574,  ..., -0.0534, -0.0528, -0.0523],\n",
       "          ...,\n",
       "          [-0.0561, -0.0564, -0.0566,  ..., -0.0563, -0.0561, -0.0559],\n",
       "          [-0.0558, -0.0559, -0.0559,  ..., -0.0561, -0.0563, -0.0565],\n",
       "          [-0.0556, -0.0554, -0.0553,  ..., -0.0559, -0.0565, -0.0572]],\n",
       "\n",
       "         [[ 0.0903,  0.0902,  0.0900,  ...,  0.0920,  0.0920,  0.0920],\n",
       "          [ 0.0903,  0.0900,  0.0897,  ...,  0.0924,  0.0923,  0.0922],\n",
       "          [ 0.0902,  0.0898,  0.0894,  ...,  0.0927,  0.0925,  0.0923],\n",
       "          ...,\n",
       "          [ 0.0788,  0.0787,  0.0785,  ...,  0.0849,  0.0856,  0.0863],\n",
       "          [ 0.0790,  0.0790,  0.0789,  ...,  0.0845,  0.0850,  0.0856],\n",
       "          [ 0.0793,  0.0793,  0.0793,  ...,  0.0840,  0.0844,  0.0848]],\n",
       "\n",
       "         [[ 0.0206,  0.0210,  0.0214,  ...,  0.0267,  0.0264,  0.0260],\n",
       "          [ 0.0213,  0.0218,  0.0222,  ...,  0.0273,  0.0271,  0.0269],\n",
       "          [ 0.0221,  0.0226,  0.0231,  ...,  0.0280,  0.0279,  0.0278],\n",
       "          ...,\n",
       "          [ 0.0122,  0.0122,  0.0122,  ...,  0.0180,  0.0179,  0.0178],\n",
       "          [ 0.0126,  0.0126,  0.0126,  ...,  0.0186,  0.0185,  0.0184],\n",
       "          [ 0.0129,  0.0130,  0.0130,  ...,  0.0192,  0.0191,  0.0190]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {i: v for i, v in enumerate(user_label)}\n",
    "id_to_label[255] = 'unlabel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 543)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label_names for img {1: 'facade', 6: 'balcony', 10: 'pillar', 11: 'shop', 255: 'unlabel'}\n"
     ]
    }
   ],
   "source": [
    "prediction = out_logit.argmax(axis=-1).squeeze()   # (h, w)\n",
    "probs = out_logit.max(axis=-1).squeeze()  # (h, w)\n",
    "high_prob_mask = probs > 0.5\n",
    "\n",
    "mask = high_prob_mask\n",
    "prediction[~mask] = 255\n",
    "\n",
    "labels = np.unique(prediction)\n",
    "label_names = {i: id_to_label[i] for i in labels}\n",
    "# label_names = [id_to_label[i] for i in labels]\n",
    "print()\n",
    "print(f'label_names for img', label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'background',\n",
       " 1: 'facade',\n",
       " 2: 'window',\n",
       " 3: 'door',\n",
       " 4: 'cornice',\n",
       " 5: 'sill',\n",
       " 6: 'balcony',\n",
       " 7: 'blind',\n",
       " 8: 'deco',\n",
       " 9: 'molding',\n",
       " 10: 'pillar',\n",
       " 11: 'shop',\n",
       " 12: 'unlabel',\n",
       " 255: 'unlabel'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 543)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31bef8f0e01d86822998708cae530d3f279653869977ee7676ea73d628f47b0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
